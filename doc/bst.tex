\documentclass{article}

\usepackage{fancybox}
\usepackage{tikz}

\usepackage{hyperref}

\usepackage{cite}

\usepackage{listings}
\usepackage{color}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\footnotesize,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  % deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frame=single,                    % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=Octave,                 % the language of the code
  % otherkeywords={*,...},           % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=2,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,                   % sets default   tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}

% \language=[Objective]{Caml}


\title{Some notes on binary search trees}
\date{\today}
\author{David M. Doolin}


\begin{document}

\maketitle

\abstract{A few notes on binary search trees and their implementations
in various programming languages.}



\section{Introduction}


The following topics will be discussed:

\begin{itemize}

\item Differences in implementations between programming languages.
\item How best to containerize, including pure tree node, tree wrapper with
node class, abstracting keys.
\item Theory and performance.

\end{itemize}


\section{Literature review}

Skiena~\cite[pp. 77, 370, 375, 589]{skiena} has a few notes.

Aho and Ullman~\cite[pp. 210]{rosen} define height and depth for nodes in a binary tree.

\begin{quote}
The height of a node n is the length of a longest path from n to
a leaf. The height of the tree is the height of the root. The depth or level of
a node n is the length of the path from the root to n.
\end{quote}

Cormen et al.~\cite{cormen:th:1990} remains a classic reference.

Rosen~\cite[pp. 757-760]{rosen} discusses three uses for binary search trees:

\begin{enumerate}
\item storing items from a list such that they can be easily found;
\item finding an object in a collection of similar objects;
\item efficiently encoding characters in a bit string.
\end{enumerate}

Sedgewick~\cite{sedgewick:r1990}.

O'Rourke~\cite{orourke:j1998}.

Manber~\cite[p. 87, Ex. 4.8]{manber:u1989} provides an interesting exercise:
show the AVL tree formed by inserting the ordered sequence $[1, 2, \ldots, 20]$.

\section{The Binary Search Tree}

Two main ideas:

\begin{enumerate}
\item Operations for manipulating BSTs;
\item intrinsic properties of BSTs.
\end{enumerate}

Operations include:

\begin{itemize}
\item insert node
\item depth-first search
\item breadth-first search
\item node presence
\item delete node
\item node successor and predecessor
\end{itemize}

Properties include:

\begin{itemize}
\item height
\item depth
\item maximum key
\item minimum key
\item size
\item diameter
\item class (full, perfect, complete, balanced, etc.)
\end{itemize}


\subsection{Operating on the BST}


\subsubsection{Successor and predecessor}

For an ordered list of values $x_i \in [x_0, x_1,\ldots,x_k]$, the successor of
$x_i$ is $x_{i+1}$, the predecessor $x_{i-1}$.

Cormen et al.~\cite[p. 248-249]{cormen:th:1990} provide a succinct algorithm for
determining the successor given each node is linked to its parent.

A decision has to made regarding the definition of minimum and maximum
elements in the tree. The choices are having the relevant successor or
predecessors of such elements either be nil or be the node. For this implementation,
maximum nodes are their own successors and minimum nodes are their
own predecessors.

Here's an implementation in Python. The nodes do not have a parent
pointer, so the parent must be passed along the recursion, along with
the correct predecessor.

\lstset{language={Python}}
\begin{lstlisting}[frame=single]
def get_predecessor(self, node, parent, predecessor):
    if parent.right == self:
        predecessor = parent

    if node.key == self.key:
        if self.left is not None:
            return self.left.minimum()
    else:
        return predecessor

    if node.key < self.key:
        if self.left is not None:
            return self.left.get_predecessor(node, self, predecessor)
    else:
        if self.right is not None:
            return self.right.get_predecessor(node, self, predecessor)

def predecessor(self, node):
    return get_predecessor(node, self, node)
\end{lstlisting}

Implementing {\tt successor} is easy, use right for left, and find the
maximum where predecessor finds the minimum.



\subsection{Properties of BST}


\subsubsection{Maximum and minimum}

Maximum and minimum elements of binary search trees are probably the easiest
algorithms to both understand and implement. The maximum is the right-most
node, the minimum the left-most, finding either means traversing the tree
to the appropriate leaf, and returning that node which has no children.

The maximum function written in Ruby is particularly elegant,
we take advantage of Ruby 2.3.x's ``safe navigation'' operator {\tt \&}:
\lstset{language={Ruby}}
\begin{lstlisting}[frame=single]
def maximum:
  self&.maximum || self
end
\end{lstlisting}

\subsection{Collisions or duplicate values}

None the preceding references explicitly discuss collisions.

\begin{itemize}
\item The duplicate key can be added to the tree, either silently or with a warning.
\item The duplicate key is not added to the tree, either silently or with a warning.

\item In Ruby, does replacing a node in a tree leak memory, or will the deleted node
get garbage collected? How about Python?

\item How to delete in c/c++ such that memory isn't leaked? This should be easier,
call delete after the node is orphaned.
\end{itemize}

\section{Persistence}

Here are some ways to store the structure in text format:

\begin{enumerate}
\item Write to nested json. This requires writing out from the top
down. Should be able to do this by converting to hash, then
writing to json. Reading in is the reverse. How to convert a
hash to a binary tree? Maybe this is where to use combinator.

\item CSV: does this require top down, or can it be done by traversing?
Does it require a parent pointer?

\item Yaml: how are references handled?
\end{enumerate}


\section{Breadth-first traversal}

Breadth-first traveral can be used for searching, for determining whether a key exists,
or for writing out the tree in flat format with rows and pointers.

For persistence, we have the following:

\begin{itemize}
\item At each node we can store pointers to each child.
\item We can store the start and the stop of each row separately.
\item We can store an array of arrays, where each of the arrays is
      one level of the tree.
\end{itemize}

[
 [root],
 [ root.left, root.right],
 [...]
]

Can all the pointers be stored in one pass, then process in a second pass,
or can the nodes be processes as the breadth-first traverse proceeds?



\section{Containerizing}

\subsection{C++ templating}

\subsection{C struct inclusion}

\subsection{Ruby module inclusion}

It's not difficult to encode binary search tree capability into a Ruby module.
The module provides all the necessary instance binary search tree methods, and
raises errors when necessary overriding has not been implemented in the
including class.

The usual caveats about instance variables referenced in modules applies,
particularly that the including class must define the key for the tree.

\section{References}

\bibliography{references}{}
\bibliographystyle{plain}

\section{Summary}

\appendix

\section{Implementation}

Implementing binary search trees is superficially very easy. Nevertheless,
a number of design decisions must be made.

\subsection{Handling null/NULL/nil/etc}

Key to any BST algorithm is the notion that leaf nodes are represented
by empty leaf nodes. Empty nodes have no key, no value, and need not be
instantiated. They must, however, be denoted in some way, which is
usually accomplished by setting the relevant child pointers (left and
right) to whatever the programming language regards as a ``non-value.''
For example, in C this is {\tt NULL}, in C++ {\tt nullptr}, in Python {\tt None}.

(It would be possible to define a global external node.)

\subsection{Tree/Node interaction}

Trees are abstract data types. This makes trees easy to reason about.
Implementing a tree requires dealing with a number of subtle issues.
Since Trees are usually described in terms of the Nodes comprising
the Tree, some thought about differentiating Trees and Nodes is in order.

\subsubsection{Implicit structure}

Given some class, record, structure or whatever language feature which contains
data and supports function invocation, adding left and right pointers,
appropriate comparators, and insert and find methods suffices to provide
dictionary capability to the given language feature. However, trees require a
root, and managing this root increases the complexity whatever application
system requires the data sorted into the tree. Provision needs to be made for
the root changing, or even being deleted.

\subsubsection{Tree container}

Another way to implement trees is to create a tree container which implements
insert, search, etc. The implementation provided by the tree container could
implement the functionality itself, or call an implementation provided by
the node element.


\subsection{Testing}

Two ways of arranging tests include:
\begin{enumerate}
\item Group tests by method or function, ensuring a number of different
trees pass the method being tested.
\item Group tests by the tree, ensuring each operation on that particular tree
executes correctly.
\end{enumerate}

Traditionally, in Test-Driven Design (TDD), a method test is created with a simple example.
The method is then implemented as simply as possible to ensure the example passes.
More complex examples are created, and the method's implementation modified as necessary
to ensure tests pass. For example, when implementing {\tt insert}, it makes sense
to write a test specification to check the a node is correctly inserted into an
empty tree to form the root, another test specification to ensure the inserting
to the left of root works correctly, to the right of root, and so on. However,
when implementing, say, {\tt size}, the same sort of procedure follows in test-driven
development: test the null case, then the cases 1 node, 2 nodes, etc.

Once the data structure is implemented, this TDD process results in a large number
of redundant tests.

Grouping tests by data structure examples puts a much larger burden on TDD,
but provides a different perspective. These tests may be more effective once an
initial implementation is created. Then, pathological data structures can be
created and tested in detail.


A binary search tree using first 10 primes for keys:

%\ovalbox{%
  \begin{tikzpicture}[level/.style={sibling distance=50mm/#1}]
  \node [circle,draw] (z){$17$}
    child {node [circle,draw] (a) {$5$}
      child {node [circle,draw] (b) {$3$}
        child {node [circle, draw] (c) {$2$}}
        child {node (ca) {}}
      }
      child {node [circle,draw] (g) {$7$}
        child {node (ga) {}}
        child {node [circle,draw] (gb) {$11$}
          child {node {}}
          child {node [circle,draw] (gc) {$13$}}
        }
      }
    }
    child {node [circle,draw] (j) {$23$}
      child {node [circle,draw] (k) {$19$}}
    child {node [circle,draw] (l) {$29$}}
  };
\end{tikzpicture}
%}

This tree contains a number of pathologies.

\subsubsection{Insert}



\subsubsection{Collect}

Test driving may induce more tests than are strictly necessary.

\begin{enumerate}
\item Single node
\item 2 node tree right
\item 2 node tree left
\item arbitrary tree
\end{enumerate}

\subsection{Search}

Here is the algorithm to find a node in a binary search tree using the key:

\lstset{language={Python}}
\begin{lstlisting}[frame=single]

def search(self, key):
    if key == self.key:
        return self

    if key < self.key:
        if self.left is not None:
            self.left.search(key)
    else:
        if self.right is not None:
            self.right.search(key)
\end{lstlisting}

\subsubsection{Testing search}

Test cases:
\begin{enumerate}
\item finds nil with an empty tree
\item finds a node in a single node tree
\item finds the left child and right child in two node trees
\item find leaf node in tree with height greater than 1
\item finds nil when key is not in the tree
\end{enumerate}

\subsubsection{Delete}

Delete depends on search, so that will need to be implemented everywhere first.

Other functions which are helpful for implementing delete correctly
are bst?, depth and size. These functions can all be used in the testing
code.

Write out a plan for implementing delete in java, python, c++ and lua,

\begin{itemize}
  \item including tree/node interaction, list of trees to work with,
  \item implementations for search, size, depth, and bst?
  \item algorithm writeup in bst doc, etc.
  \item After implementing and writeup, compare with clr.
\end{itemize}

\lstset{language={Python}}
\begin{lstlisting}[frame=single]

def delete(self, key):
    # delete algorithm
\end{lstlisting}


Test cases:
\begin{enumerate}
\item deletes nil with an empty tree
\item deletes a node in a single node tree
\item deletes the left child and right child in two node trees
\item deletes leaf node in tree with height greater than 1
\item deletes nil when key is not in the tree
\end{enumerate}


\subsubsection{AVL testing}

Some links for AVL trees:

\begin{itemize}
\item  \href{http://adtinfo.org/libavl.html/Step-3-in-AVL-Insertion.html}{%
http://adtinfo.org/libavl.html/Step-3-in-AVL-Insertion.html}
\item \href{http://eniac.cs.qc.cuny.edu/andrew/csci700-11/lecture7.pdf}{%
http://eniac.cs.qc.cuny.edu/andrew/csci700-11/lecture7.pdf}
\item \href{http://software.ucv.ro/~mburicea/lab6ASD.pdf}{%
http://software.ucv.ro/~mburicea/lab6ASD.pdf}
\end{itemize}

\paragraph{Insert}

\begin{itemize}
\item Draw out the cases requiring rotations. This will include 3, 4, 5, and 6
node examples, but probably no more than 6, possibly no more than 5.
\item Create a number of nodes.
\item Build the tree in sorted order starting with the smallest node.
This will build out the tree from the left, performing right, or ccw, rotations.
\item As each node is inserted, check the size, weight, balance and which node is currently the root of the tree.
\item Write an expectation for the rotate\_ccw method to ensure it's called the correct number of times.
\end{itemize}

Repeat this using the same list in decreasing order to build the tree from the
right.

Repeat inserting the keys in sorted order so the avl operation maintains
balance. Write an expectation to ensure no rotations are performed.



\paragraph{Delete}

Do something similar as above, check
rotations and balance after deletion.


\subsubsection{RB testing}

Some links for RB trees:

\begin{itemize}
\item \href{http://eniac.cs.qc.cuny.edu/andrew/csci700-11/lecture8.pdf}{%
http://eniac.cs.qc.cuny.edu/andrew/csci700-11/lecture8.pdf}
\end{itemize}

\subsection{Language listings}

\lstset{language=[Objective]{Caml}}
\begin{lstlisting}[frame=single]  % Start your code-block

open OUnit2;;

let test1 test_ctxt = assert_equal "x" (Foo.unity "x");;
let test2 test_ctxt = assert_equal 100 (Foo.unity 100);;

(* Name the test cases and group them together *)
let suite =
"suite">:::
 ["test1">:: test1;
  "test2">:: test2]
;;

let () =
  run_test_tt_main suite
;;
\end{lstlisting}

\section{Selected exercises and problems}


\subsection{CLR}

\subsubsection{Problem 3-4: Number of different binary trees}

The goal of this problem is to determine the number of binary
trees possible given $n$ nodes.

\paragraph{Part a} For $b_0 = 1$ and $n \geq 1$,

\[
b_n = \sum_{k=0}^{n-1} b_kb_{n-1-k}.
\]

Let's do some examples, starting with $n = 1$, giving $k = 0$:

\begin{itemize}
\item [$k=0$] $b_0 = 1, b_1$
\end{itemize}

\section{Tikz}

% \href{http://www.texample.net/tikz/examples/merge-sort-recursion-tree/}{From texample.net}

\ovalbox{%
  \begin{tikzpicture}[level/.style={sibling distance=50mm/#1}]
  \node [circle,draw] (z){$17$}
    child {node [circle,draw] (a) {$5$}
      child {node [circle,draw] (b) {$3$}
        child {node [circle, draw] (c) {$2$}}
        child {node (ca) {}}
      }
      child {node [circle,draw] (g) {$7$}
        child {node (ga) {}}
        child {node [circle,draw] (gb) {$11$}
          child {node {}}
          child {node [circle,draw] (gc) {$13$}}
        }
      }
    }
    child {node [circle,draw] (j) {$23$}
      child {node [circle,draw] (k) {$19$}}
    child {node [circle,draw] (l) {$29$}}
  };
\end{tikzpicture}
}



\href{http://www.texample.net/tikz/examples/merge-sort-recursion-tree/}{From texample.net}

\ovalbox{%
%\begin{tikzpicture}[level/.style={sibling distance=60mm/#1}]
\begin{tikzpicture}[level/.style={sibling distance=40mm/#1}]
\node [circle,draw] (z){$n$}
  child {node [circle,draw] (a) {$\frac{n}{2}$}
    child {node [circle,draw] (b) {$\frac{n}{2^2}$}
      child {node {$\vdots$}
        child {node [circle,draw] (d) {$\frac{n}{2^k}$}}
        child {node [circle,draw] (e) {$\frac{n}{2^k}$}}
      }
      child {node {$\vdots$}}
    }
    child {node [circle,draw] (g) {$\frac{n}{2^2}$}
      child {node {$\vdots$}}
      child {node {$\vdots$}}
    }
  }
  child {node [circle,draw] (j) {$\frac{n}{2}$}
    child {node [circle,draw] (k) {$\frac{n}{2^2}$}
      child {node {$\vdots$}}
      child {node {$\vdots$}}
    }
  child {node [circle,draw] (l) {$\frac{n}{2^2}$}
    child {node {$\vdots$}}
    child {node (c){$\vdots$}
      child {node [circle,draw] (o) {$\frac{n}{2^k}$}}
      child {node [circle,draw] (p) {$\frac{n}{2^k}$}
        child [grow=right] {node (q) {$=$} edge from parent[draw=none]
          child [grow=right] {node (q) {$O_{k = \lg n}(n)$} edge from parent[draw=none]
            child [grow=up] {node (r) {$\vdots$} edge from parent[draw=none]
              child [grow=up] {node (s) {$O_2(n)$} edge from parent[draw=none]
                child [grow=up] {node (t) {$O_1(n)$} edge from parent[draw=none]
                  child [grow=up] {node (u) {$O_0(n)$} edge from parent[draw=none]}
                }
              }
            }
            child [grow=down] {node (v) {$O(n \cdot \lg n)$}edge from parent[draw=none]}
          }
        }
      }
    }
  }
};
\path (a) -- (j) node [midway] {+};
\path (b) -- (g) node [midway] {+};
\path (k) -- (l) node [midway] {+};
\path (k) -- (g) node [midway] {+};
\path (d) -- (e) node [midway] {+};
\path (o) -- (p) node [midway] {+};
\path (o) -- (e) node (x) [midway] {$\cdots$}
  child [grow=down] {
    node (y) {$O\left(\displaystyle\sum_{i = 0}^k 2^i \cdot \frac{n}{2^i}\right)$}
    edge from parent[draw=none]
  };
\path (q) -- (r) node [midway] {+};
\path (s) -- (r) node [midway] {+};
\path (s) -- (t) node [midway] {+};
\path (s) -- (l) node [midway] {=};
\path (t) -- (u) node [midway] {+};
\path (z) -- (u) node [midway] {=};
\path (j) -- (t) node [midway] {=};
\path (y) -- (x) node [midway] {$\Downarrow$};
\path (v) -- (y)
  node (w) [midway] {$O\left(\displaystyle\sum_{i = 0}^k n\right) = O(k \cdot n)$};
\path (q) -- (v) node [midway] {=};
\path (e) -- (x) node [midway] {+};
\path (o) -- (x) node [midway] {+};
\path (y) -- (w) node [midway] {$=$};
\path (v) -- (w) node [midway] {$\Leftrightarrow$};
\path (r) -- (c) node [midway] {$\cdots$};
\end{tikzpicture}}


\end{document}
