\documentclass{article}

\include{preamble}

\title{CLRS, 3rd Edition}
\date{\today}
\author{David M. Doolin}


\begin{document}

\maketitle

\abstract{CLRS}

\tableofcontents


\section{Selected exercises and problems}


%%% TODO: get rid of this heapsort stuff.
\setcounter{section}{6}
\section{Heap sort}

\subsection{6.1-5} Is an array in sorted order a min-heap?

Yes, because for every index $i = 1, 2, 3,\ldots, A[i-1] \leq A[i]$,
which satisifies the min-heap property.


\subsection{Preliminaries}

%%%%% ^^^^ TODO: get rid of heapsort ^^^^^

\setcounter{section}{11}
\section{Binary search trees}


\subsection{Preliminaries}


\subsubsection{Draw various height trees}

At some point in the future, I may actually draw these as for
display in this document. For now, here is the sequence
$[1, 4, 5, 10, 16, 17, 21]$ used to create binary search trees
of various heights. Each of the following sequences represents
a breadth-first listing, which corresponds to insertion order.

\begin{itemize}
  \item Height 2: $[10, 4, 17, 1, 5, 16, 21]$
  \item Height 3: $[5, 1, 17, 4, 16, 21, 10]$
  \item Height 4: $[5, 1, 10, 4, 16, 17, 21]$
  \item Height 5: $[4, 1, 5, 10, 16, 17, 21]$
  \item Height 6: $[1, 4, 5, 10, 16, 17, 21]$
\end{itemize}

\subsubsection{Compare binary-search-tree and min-heap}

What is the difference between the binary-search-tree property and the min-heap
property (p. 153)? Can the min-heap property be used to print out the keys of
an $n$-node tree, in sorted order, in $O(n)$ time?  Show how, or explain why
not.

Let's start with definitions.
The min-heap property:

\begin{equation}
  A[\mathrm{parent}(i)] \leq A[i].
\end{equation}

The binary-search-tree property: For $x$ a node in a in binary search tree,
$y$ in the left subtree implies $y.\mathrm{key} \leq x.\mathrm{key}$, and
$y$ in the right subtree implies $y.\mathrm{key} \geq x.\mathrm{key}$.

The difference is the min-heap requires \emph{both} children to be
greater than the root node, violating the binary-search-tree property.

In-order printing the keys of an arbitrary min-heap cannot be done in $O(n)$
for either breadth-first, or any depth-first traversal without inducing
additional comparisons at each level. Consider the min-heap $[2, 8, 4]$.
Breadth-first traversal requires comparing elements 2 and 3.

There may be a result elsewhere proving sorting requires $O(n\ln n)$,
this would be a good place to cite that result if the conditions hold.

\subsubsection{Iterative algorithm for in-order tree walk}

Here's an implementation using a stack:

\lstset{language={ruby}}
\begin{lstlisting}[frame=single,title=Iterative inorder traverse]
def inorder_iterate
  output = []
  stack = [root]

  while stack.last&.left
    stack << stack.last.left
  end

  while !stack.empty?
    current = stack.pop
    output << current&.key
    if current&.right
      stack << current.right
      while stack.last&.left
        stack << stack.last.left
      end
    end
  end
  output.compact
end
\end{lstlisting}

This is not a fulfilling implementation. First, CLRS hints at an
`elegant' solution not requiring a stack, provided we can compare pointers
(which we can). Second, even using the stack, there is a block of
repeat code to dig out the lowest leftmost, and that smells. There should
be a cleaner implementation using a stack.


\subsubsection{Derive recursive pre- and post-order walks}

Implementing pre- and post-order-traverse in C is not difficult. Getting
such traverses to do work requires passing in an argument to handle
the accumulated state, and a function with which to compute that state.
This would be handled by closures in languages which support closures.
Passing in both function pointer and data allows the passed in function
to properly type and dereference the \texttt{userdata}.

\lstset{language={c}}
\begin{lstlisting}[frame=single,title=Post-order traverse]
void
post_order_traverse(Node * n, Callback callback, void * userdata) {
  if (n->left  != NULL) { post_order_traverse(n->left, callback, userdata); }
  if (n->right != NULL) { post_order_traverse(n->right, callback, userdata); }
  if (callback != NULL) { callback(n, userdata); }
}
\end{lstlisting}

\lstset{language={c}}
\begin{lstlisting}[frame=single,title=Pre-order traverse]
void
pre_order_traverse(Node * n, Callback callback, void * userdata) {
  if (callback != NULL) { callback(n, userdata); }
  if (n->left  != NULL) { in_order_traverse(n->left, callback, userdata); }
  if (n->right != NULL) { in_order_traverse(n->right, callback, userdata); }
}
\end{lstlisting}


\subsubsection{Worst case comparisons on sorted data}

%%%%%%%%%% Section 2

\subsection{Querying a Binary Search Tree}

\subsubsection{Valid search sequence}

\begin{quote}
Suppose that we have numbers between 1 and 1000 in a binary search tree, and we
want to search for the number 363. Which of the following sequences could not be
the sequence of nodes examined?

a. 2, 252, 401, 398, 330, 344, 397, 363.

b. 924, 220, 911, 244, 898, 258, 362, 363.

c. \textbf{INVALID} 925, 202, 911, 240, 912, 245, 363.

d. 2, 399, 387, 219, 266, 382, 381, 278, 363.

e. \textbf{INVALID} 935, 278, 347, 621, 299, 392, 358, 363.
\end{quote}

Search and insertion are conceptually similar in binary search
trees. To determine validity, each sequence above was drawn as
a binary search tree. After drawing, it's obvious which sequences
are not valid for finding the desired node.

\subsubsection{Iterative implementations of min and max}

The original problem calls for recursive implementations for minimum
and maximum elements, but I already derived those, so this exercise
is changed to provide the iterative implementations. Here's the
Ruby code for \texttt{minimum}:

\lstset{language={Ruby}}
\begin{lstlisting}[frame=single]
def minimum
  min = self.left
  while min.left
    min = min.left
  end
  min
end
\end{lstlisting}

The \texttt{maximum} function works by successively calling the right
child, as one might suspect.

\subsubsection{Tree predecessor}

This is already written, recursively, without using parent pointer.


\subsubsection{Prof. Bunyan's key sorting claim}

\subsubsection{Successor and predecessor for node with 2 children}

\subsubsection{Ancestor nodes}

\subsubsection{In-order walk using minimum and successor}

\subsubsection{Complexity of successive calls to successor}

\subsubsection{Node parent-child key relationship}

%%%%%%%%%%% Section 3

\subsection{Insertion and deletion}

\subsubsection{Recursive tree insertion}

\subsubsection{Cost of repeated insertion and searching}

\subsubsection{Cost of sorting with binary search tree}

\subsubsection{Is deletion commutative?}

\subsubsection{Implement search, insert, delete with successor}

\subsubsection{Choose predecessor for delete}

%%%%%%%%%%%% Section 4

\subsection{Randomly built binary search trees}

\subsubsection{Prove Eq. 12.3}

\subsubsection{Depth versus height}

\subsubsection{Differentiate randomly built trees}


\subsubsection{Prove $2^x$ is convex}

Proving $2^x$ is convex is a bit tricky, and leans on a fairly deep result about
exponentiation which I don't really understand yet. We can start with a definition
of convexity, with the assumption $x\in\mathbb{R}$:

\begin{equation}
  f''(x) \geq 0.
\end{equation}

Differentiating $f(x) = 2^z$ twice,

\begin{equation}
  f' = 2^x \ln 2, f'' = 2^x\ln^2 2.
\end{equation}

Showing the second derivative is positive requires showing that the
terms in the product are both positive, or both negative. Since $\ln 2$
is positive, we must show that $2^x \geq 0$ for all $x$.

By definition,

\begin{equation}\label{eq:exp_series}
  e^x = \sum_{n=0}^\infty \frac{x^n}{n!}.
\end{equation}

Also by definition,

\begin{equation}\label{eq:log2}
  2^x = e^{x\ln 2}
\end{equation}

(\textit{This seems wrong, redo this to be more explicit.})

Using the result $e^xe^y = e^{(x+y)}$, we note that $e^xe^{-x} = 1$, implying

\begin{equation}\label{eq:invert}
  e^{-x} = \frac{1}{e^x}.
\end{equation}

For $x > 0$, every term in the power series expansion
(Eq.~\ref{eq:exp_series}) for $e^x$ is positive.
From Eq.~\ref{eq:invert}, $e^x$ and $e^{-x}$ are positive for all $x\in\mathbb{R}$. The result
$2^x > 0$ for all $x\in\mathbb{R}$ follows by substitution using
Eq.~\ref{eq:log2}. Hence $2^x\ln^2 2 > 0$ and $2^x$ is convex.

\begin{comment}
Substituting and expanding:

\begin{equation}
  2^x = 1 + x\ln 2 + \frac{x^2 \ln^2 2}{2!} + \frac{x^3 \ln^3 2}{3!} + \cdots.
\end{equation}

For $x > 0, 2^x$ is clearly positive. For $x = 0, 2^0 = 1$, again positive. When $x < 0$,

\begin{equation}
  2^{-x} = 1 - x\ln 2 + \frac{x^2 \ln^2 2}{2!} - \frac{x^3 \ln^3 2}{3!} + \frac{x^4 \ln^4 2}{4!}
  - \frac{x^5 \ln^5 2}{5!} + \cdots.
\end{equation}
\end{comment}

\subsubsection{Randomized Quick Sort permutations}

\subsection{Problems}

\subsubsection{Problem 12-1}

\subsubsection{Problem 12-2}

\subsubsection{Problem 12-3}

\subsubsection{Problem 12-4: Number of different binary trees}

The goal of this problem is to determine the number of binary
trees possible given $n$ nodes.

\paragraph{Part a} For $b_0 = 1$ and $n \geq 1$,

\[
b_n = \sum_{k=0}^{n-1} b_kb_{n-1-k}.
\]

Let's do some examples, starting with $n = 1$, giving $k = 0$:

\begin{itemize}
\item [$k=0$] $b_0 = 1, b_1$
\end{itemize}

\paragraph{Part b.} Let $B(x)$ be the generating function

\begin{equation}
B(x) = \sum_{n=0}^{\infty}b_nx^n.
\end{equation}

Show that $B(x) = xB(x)^2 + 1$, and

\begin{equation}
B(x) = \frac{1}{2x}(1-\sqrt{1-4x}).
\end{equation}

Make the substitution $z = B(x)$ and rewrite:

\begin{equation}
  xz^2 - z + 1 = 0,
\end{equation}

a straightforward quadratic equation.

\paragraph{Part c.}

\paragraph{Part d.}

This concludes the exercises and problems for Chapter 12.

\appendix

\section{Detours}

Detours fill in a bit of mathematical background material.
First, a short detour into generating functions.

\subsection{Detour into generating functions}

This example is taken from Cormen et al.~\cite[p. 74]{cormen:th:1990}
Problem 4-6.

\begin{align}
F(z) & = \sum_{i=0}^{\infty} F_ix^i\\
\label{eqn:fibonacci_opsgf}
     & = 0 + z + z^2 + 2z^3 + 3z^4 + 5z^5 + 8z^6 + 13z^7 + 21z^8+\cdots
\end{align}

This is inconvenient for a closed form solution, so we need to do a bit of
manipulation. First, multiply both sides by $Z$:

\begin{equation}
\label{eqn:zfibonacci_opsgf}
zF(z) = z^2 + z^3 + 2z^4 + 3z^5 + 5z^6 + 8z^7 + 13z^8 + 21z^9+\cdots
\end{equation}

Now subtract~\ref{eqn:zfibonacci_opsgf} from~\ref{eqn:fibonacci_opsgf} to
obtain

\begin{align}
F(z) - zF(z) & = z + z^3 + z^4 + 2z^5 + 3z^6 +\cdots\\
F(z) - zF(z) & = z + z^2(0 + z + z^2 + 2Z^3 + 3z^4 +\cdots)\\
             & = z + z^2F(z)\\
        F(z) & = \frac{z}{1-z-z^2}.
\end{align}


\subsection{Detour into partial fraction expansion}

The idea of partial fraction expansion is to reduce some
complicated ratio of functions into a sum of simpler functions.
Practical uses include analytic solutions for differential equations
using the Laplace Transform~\cite[p. 347]{nagle:rk1989}, and simplifying
generating functions, as will done for deriving a formula for the
$nth$ Catalan number.

Here's a simple example:

\begin{equation}
\frac{-4x-10}{x^2+4x+3} = \frac{A}{x+1} + \frac{B}{x+3}
\end{equation}

Solving for $A$ and $B$ can be done using a system of linear equations,
or, in this case, simply assuming the values $x = -1$ and $x = -5$
to solve for $A$ and $B$ respectively. Either technique results in $A = -3$ and
$B = -1$:
\begin{equation}
\frac{-4x-10}{x^2+4x+3} = \frac{-3}{x+1} + \frac{-1}{x+3},
\end{equation}
which can of course be verified by summing the right hand side.

\paragraph{Double factorial}

(A bunch of the following was copied from Wikipedia. Over the next few
revisions of this section I'll rework into my own material. What's here
now is just to get the grunt work of the equation formatting finished.
This comment will be deleted as well.)

The double factorial for $n$, denoted $n!!$, is defined as

\begin{equation}
  n!! = \prod_{k=0}^{\left\lceil\frac{n}{2}\right\rceil - 1} (n-2k) = n (n-2) (n-4) \cdots
\end{equation}

\begin{equation}
  \prod_{k=1}^\frac{n}{2} (2k) = n(n-2)(n-4)\cdots 4\cdot 2\,,
\end{equation}

\begin{equation}
  \prod_{k=1}^\frac{n+1}{2} (2k-1) = n(n-2)(n-4)\cdots 3\cdot 1 \,.
\end{equation}

For an even positive integer $n = 2k, k \geq 0$, the double factorial may be expressed as

\begin{equation}\label{eq:df-even}
{\displaystyle n!!=2^{k}k!\,.}
\end{equation}

For odd $n = 2k - 1, k \geq 1$, it has the expressions
\begin{equation}\label{eq:df-odd}
{\displaystyle n!!={\frac {(2k)!}{2^{k}k!}}={\frac {n!}{(n-1)!!}}\,.}
\end{equation}

All together:
\begin{equation}
n!! = \begin{cases}
  2^kk! & \text{when } x \text{ is even}, k = \frac{n}{2} \\
  \frac{(2k)!}{2^kk!} & \text{when } x \text{ is odd}, k = \frac{(n+1)}{2}
\end{cases}
\end{equation}


This next spiffy little result is implied by both
Eqs.~\ref{eq:df-even} and~\ref{eq:df-odd}:
\begin{equation}
  (n-1)!!n!! = \frac{(2k)!}{2^kk!}2^kk! = n!
\end{equation}

In this expression, when $n$ is even the first denominator equals $(2k)!!$
and cancels the unwanted even factors from the numerator. When $n$ is odd,
$k$ assumes values appropriate to $n$ and $n-1$. This brings us to the binomial
coefficients:

\[
  \binom{n}{k} = \frac{n!}{k!(n-k)!}
\]

\href{https://en.wikipedia.org/wiki/Double\_factorial}{Wikipedia} has a
really cool example on perfect matchings for complete graphs, which I could use
for a generating function practice perhaps.

The upshot is when expressions such as $1\cdot3\cdot5\cdot7\cdots$ and
$2\cdot4\cdot6\cdot8\cdots$ appear, we have well-understood tools for dealing
with them.

\subsection{Detour into Taylor series and Binomial Expansion}

Cormen et al.~\cite[p. 262]{cormen:th:1990} gives Taylor Series definition as
(there is an error in the edition cited here, see the Errata for clarification):

\begin{equation}
f(x) = \sum_{k=0}^{\infty} \frac{f^{(k)}(a)}{k!}(x-a)^k,
\end{equation}

and suggests expanding the radical term in the generating function
$\sqrt{1-4x}$ around $0$.

{\bf TODO: write out a few derivatives of the radical to construct
the Taylor Series.}

For binomial expansion, we have

\begin{equation}
  (1 + z)^k = 1 + kz + \frac{1}{2!}k(k - 1)z^2 + \frac{1}{3!}k(k - 1)(k - 2)z^3 + \cdots
\end{equation}

There are several keys to deriving the quantity we're looking for.
The first is using the substitution $z = -4x$, with $k = 1/2$. This way the expansion
can proceed unencumbered with extraneous details. Another key is evaluating the
numerator separately. Observe:

\textbf{THESE AREN'T REALLY SUMS AS WRITTEN, IT'S BOGUS, REWRITE IT CORRECTLY.}

Consider the sequence $k, k(k-1),\dots, k(k - 1)(k - 2)\cdots(k - n + 1)$.

\begin{equation}
  \frac{1}{2},
  \left(\frac{1}{2}\right)\left(-\frac{1}{2}\right),
  \left(\frac{1}{2}\right)\left(-\frac{1}{2}\right)\left(-\frac{3}{2}\right),
  \left(-\frac{1\cdot3\cdot5}{16}\right),
  \left(-\frac{1\cdot3\cdot5\cdot7}{32}\right)
\end{equation}

\begin{equation}
  \frac{1}{2},
  \frac{1}{4},
  \frac{1\cdot3}{8},
  \frac{1\cdot3\cdot5}{16},
  \frac{1\cdot3\cdot5\cdot7}{32}
\end{equation}

\begin{equation}
  \frac{0!!}{2},
  \frac{1!!}{4},
  \frac{3!!}{8},
  \frac{5!!}{16},
  \frac{7!!}{32}
\end{equation}


%%%%%%%%%%%%%%%%%%%%% End of body of article %%%%%%%%%%%%%%%%%%%%%%%


\bibliography{references}{}
\bibliographystyle{plain}

\end{document}
